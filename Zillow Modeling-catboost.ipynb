{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba as nb\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# display set up\n",
    "%matplotlib inline\n",
    "%precision 4\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for memory reduction\n",
    "@nb.jit()\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prop_2016 = pd.read_csv('data/prop_2016.csv')\n",
    "prop_2016 = reduce_mem_usage(prop_2016)\n",
    "\n",
    "prop_2017 = pd.read_csv('data/prop_2017.csv')\n",
    "prop_2017 = reduce_mem_usage(prop_2017)\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features(df):\n",
    "    \"\"\"\n",
    "    Drop id columns and columns not needed.\n",
    "    \"\"\"\n",
    "    # id and label (not features)\n",
    "    drop_list = ['parcelid']\n",
    "    \n",
    "    # Too many Missing Values from EDA\n",
    "    drop_list.extend(['architecturalstyletypeid','buildingclasstypeid',\n",
    "                      'decktypeid','typeconstructiontypeid'])\n",
    "    \n",
    "    # Duplicated Columns found from EDA\n",
    "    drop_list.extend(['calculatedbathnbr','finishedsquarefeet50'])\n",
    "    \n",
    "    # Highly Correlated with other related columns\n",
    "    drop_list.extend(['fullbathcnt','censustractandblock'])\n",
    "    \n",
    "    # Drop columns with low feature importance\n",
    "#     drop_list.extend(['fireplaceflag','fips','finishedsquarefeet13','poolsizesum','pooltypeid10','basementsqft',\n",
    "#                      'storytypeid','yardbuildingsqft26','finishedsquarefeet6','fireplacecnt','regionidcounty',\n",
    "#                       'propertyzoningdesc','propertycountylandusecode'])\n",
    "\n",
    "    return(df.drop(columns=drop_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(train, prop_2016, prop_2017, categorical_features):\n",
    "    \"\"\"\n",
    "    To limit the value to small numbers since values in categorical_feature is suggested to be small.\n",
    "    Now the number denoting missing values will be 0 instead of -1.\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    prop = pd.concat([train[categorical_features],\n",
    "                      prop_2016[categorical_features], \n",
    "                      prop_2017[categorical_features]], ignore_index=True)\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        encoder = LabelEncoder().fit(prop[col].astype(str))\n",
    "        train[col] = encoder.transform(train[col].astype(str))\n",
    "        prop_2016[col] = encoder.transform(prop_2016[col].astype(str))\n",
    "        prop_2017[col] = encoder.transform(prop_2017[col].astype(str))\n",
    "    del prop\n",
    "    gc.collect()\n",
    "    return(train, prop_2016, prop_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (131489, 127)\n",
      "y_train shape: (131489,)\n",
      "X_val shape: (33578, 127)\n",
      "y_val shape: (33578,)\n"
     ]
    }
   ],
   "source": [
    "# Do encoding for cateogircal features\n",
    "categorical_features = ['airconditioningtypeid','buildingqualitytypeid',\n",
    "                        'hashottuborspa','heatingorsystemtypeid','pooltypeid2','pooltypeid7',\n",
    "                        'propertylandusetypeid','rawcensustractandblock',\n",
    "                        'regionidcity','regionidneighborhood','regionidzip', 'yearbuilt','assessmentyear',\n",
    "                        'taxdelinquencyflag','taxdelinquencyyear','geo_cluster']\n",
    "\n",
    "train, prop_2016, prop_2017 = encoding(train, prop_2016, prop_2017, categorical_features)\n",
    "\n",
    "# Transform to Numpy matrices\n",
    "X = drop_features(train).drop(columns='logerror')\n",
    "y = train.logerror.values\n",
    "\n",
    "# Specify feature names\n",
    "feature_names = [col for col in X.columns]\n",
    "\n",
    "# Get categorical features\n",
    "categorical_indices = []\n",
    "for i, n in enumerate(X.columns):\n",
    "    if n in categorical_features:\n",
    "        categorical_indices.append(i)\n",
    "\n",
    "# Perform shuffled train/test split\n",
    "np.random.seed(910)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Keep outlier values (roughly outside 99% percentile) out of the training dataset\n",
    "outlier_threshold = 0.4\n",
    "mask = (abs(y_train) <= outlier_threshold)\n",
    "X_train = X_train.iloc[mask, :]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_val shape: {}\".format(X_test.shape))\n",
    "print(\"y_val shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost parameters Setting\n",
    "params = {'loss_functiomn': 'MAE',\n",
    "         'eval_metric': 'MAE',\n",
    "         'nan_mode': 'Min',\n",
    "         'iterations': 1000,\n",
    "         'l2_leaf_reg': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 5.106739281624631\n",
      "Test score: 6.86613889576145\n",
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train CatBoost Regressor with cross-validated early-stopping\n",
    "test_pool = Pool(X_test, y_test.astype(np.float64), cat_features=categorical_indices)\n",
    "\n",
    "np.random.seed(910)\n",
    "model = CatBoostRegressor(**params)\n",
    "model.fit(X_train, y_train,\n",
    "          cat_features=categorical_indices,\n",
    "          use_best_model=True, eval_set=test_pool, early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "\n",
    "# Evaluate on train and validation sets\n",
    "print(f\"Train score: {abs(model.predict(X_train) - y_train).mean() * 100}\")\n",
    "print(f\"Test score: {abs(model.predict(X_test) - y_test).mean() * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model 0\n",
      "Start training model 1\n",
      "Start training model 2\n",
      "Start training model 3\n",
      "Start training model 4\n",
      "Start training model 5\n",
      "Start training model 6\n",
      "Start training model 7\n",
      "model 0: 6.806486062415555\n",
      "model 1: 6.807822975141546\n",
      "model 2: 6.8120287008259295\n",
      "model 3: 6.810470335163292\n",
      "model 4: 6.8080887912448205\n",
      "model 5: 6.81278833983821\n",
      "model 6: 6.808338311486676\n",
      "model 7: 6.806888600212144\n"
     ]
    }
   ],
   "source": [
    "# Remove outlier (if any)\n",
    "outlier_threshold = 0.4\n",
    "mask = (abs(y) <= outlier_threshold)\n",
    "X = X.iloc[mask, :]\n",
    "y = y[mask]\n",
    "\n",
    "# Train multiple models\n",
    "bags = 8\n",
    "models = []\n",
    "params['iterations'] = 1000\n",
    "for i in range(bags):\n",
    "    print(\"Start training model {}\".format(i))\n",
    "    params['random_seed'] = i\n",
    "    np.random.seed(910)\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X, y, cat_features=categorical_indices, verbose=False)\n",
    "    models.append(model)\n",
    "    \n",
    "# Sanity check (make sure scores on a small portion of the dataset are reasonable)\n",
    "for i, model in enumerate(models):\n",
    "    print(\"model {}: {}\".format(i, abs(model.predict(X_test) - y_test).mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test_features(prop_2016, prop_2017):\n",
    "    \"\"\"\n",
    "    Helper method that prepares prop_2016 and prop_2017 for prediction.\n",
    "    \"\"\"\n",
    "    prop_2016 = drop_features(prop_2016)\n",
    "    prop_2017 = drop_features(prop_2017)\n",
    "    \n",
    "    # Create three datetime columns that does not exist in those dataset\n",
    "    prop_2016['year'] = 0\n",
    "    prop_2017['year'] = 1\n",
    "    \n",
    "    prop_2016['month'] = 8 # randomly select one month\n",
    "    prop_2017['month'] = 8 # randomly select one month\n",
    "    \n",
    "    prop_2016['quarter'] = 3 # randomly select one quarter\n",
    "    prop_2017['quarter'] = 3 # randomly select one quarter\n",
    "    \n",
    "    # Reorder to maintain categorical indices\n",
    "    prop_2016 = prop_2016[['year', 'month', 'quarter'] + list(prop_2016.columns[:-3])]\n",
    "    prop_2017 = prop_2017[['year', 'month', 'quarter'] + list(prop_2017.columns[:-3])]\n",
    "    return(prop_2016, prop_2017)\n",
    "\n",
    "def predict_and_export(models, prop_2016, prop_2017, file_name):\n",
    "    \"\"\"\n",
    "    Helper method to make predicition and export results to csv.\n",
    "    \"\"\"\n",
    "    # Construct DataFrame for prediction results\n",
    "    submission_2016 = pd.DataFrame()\n",
    "    submission_2017 = pd.DataFrame()\n",
    "    submission_2016['ParcelId'] = prop_2016.parcelid\n",
    "    submission_2017['ParcelId'] = prop_2017.parcelid\n",
    "    \n",
    "    # Prepare dataset for prediction\n",
    "    prop_2016, prop_2017 = transform_test_features(prop_2016, prop_2017)\n",
    "    \n",
    "    # Make Prediction across multiple models\n",
    "    pred_2016, pred_2017 = [], []\n",
    "    for i, model in enumerate(models):\n",
    "        print(\"Start model {} (2016)\".format(i))\n",
    "        pred_2016.append(model.predict(prop_2016))\n",
    "        print(\"Start model {} (2017)\".format(i))\n",
    "        pred_2017.append(model.predict(prop_2017))\n",
    "    \n",
    "    # Take average across all models\n",
    "    mean_pred_2016 = np.mean(pred_2016, axis=0)\n",
    "    mean_pred_2017 = np.mean(pred_2017, axis=0)\n",
    "    \n",
    "    # Formatting for submission\n",
    "    submission_2016['201610'] = [float(format(x, '.4f')) for x in mean_pred_2016]\n",
    "    submission_2016['201611'] = submission_2016['201610']\n",
    "    submission_2016['201612'] = submission_2016['201610']\n",
    "\n",
    "    submission_2017['201710'] = [float(format(x, '.4f')) for x in mean_pred_2017]\n",
    "    submission_2017['201711'] = submission_2017['201710']\n",
    "    submission_2017['201712'] = submission_2017['201710']\n",
    "    \n",
    "    submission = pd.merge(submission_2016,submission_2017, how='inner', on='ParcelId')\n",
    "    submission.to_csv(file_name, index=False)\n",
    "    print(\"Submission Successfully Created.\")\n",
    "    return(submission, pred_2016, pred_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model 0 (2016)\n",
      "Start model 0 (2017)\n",
      "Start model 1 (2016)\n",
      "Start model 1 (2017)\n",
      "Start model 2 (2016)\n",
      "Start model 2 (2017)\n",
      "Start model 3 (2016)\n",
      "Start model 3 (2017)\n",
      "Start model 4 (2016)\n",
      "Start model 4 (2017)\n",
      "Start model 5 (2016)\n",
      "Start model 5 (2017)\n",
      "Start model 6 (2016)\n",
      "Start model 6 (2017)\n",
      "Start model 7 (2016)\n",
      "Start model 7 (2017)\n",
      "Length of submission DataFrame: 2985217\n",
      "Submission header:\n",
      "   ParcelId     201610     201611     201612     201710     201711     201712\n",
      "0  10754147  1.690e-02  1.690e-02  1.690e-02  1.830e-02  1.830e-02  1.830e-02\n",
      "1  10759547  1.200e-02  1.200e-02  1.200e-02  1.530e-02  1.530e-02  1.530e-02\n",
      "2  10843547  5.100e-03  5.100e-03  5.100e-03  3.900e-03  3.900e-03  3.900e-03\n",
      "3  10859147  2.010e-02  2.010e-02  2.010e-02  2.040e-02  2.040e-02  2.040e-02\n",
      "4  10879947  9.000e-04  9.000e-04  9.000e-04  5.000e-04  5.000e-04  5.000e-04\n",
      "Wall time: 7min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "del train\n",
    "gc.collect()\n",
    "\n",
    "file_name = 'submission/final_cat.csv'\n",
    "submission, pred_2016, pred_2017 = predict_and_export(models, prop_2016, prop_2017, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
